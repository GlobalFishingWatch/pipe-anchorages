{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "from s2sphere import CellId, LatLng\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9121175d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "PORT_LIST_FLDR = './data/port_lists'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26dc5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s2_anchorage_style(lat: float, lon: float) -> str:\n",
    "    # Build the level-14 S2 cell containing this point and return the first 8 hex digits as a string\n",
    "    cid = CellId.from_lat_lng(LatLng.from_degrees(lat, lon)).parent(14)\n",
    "    # Format the 64-bit id as 16 hex chars and take the first 8 (most significant)\n",
    "    return f\"{cid.id():016x}\"[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf2d1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_overrides(df, duplicate_option = 'nothing'):\n",
    "    duplicate_options = ['keep_last', 'combine_with_ampersand','nothing']\n",
    "    if duplicate_option not in duplicate_options:\n",
    "        raise Exception(f\"{duplicate_option} not a valid duplicate_option\")\n",
    "\n",
    "    # fix messed up s2ids\n",
    "    messed_up_s2id_count = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        s2id = str(row['s2id'])\n",
    "        if ('+' in s2id) or (len(s2id) != 8):\n",
    "            df.loc[idx, 's2id'] = s2_anchorage_style(row['latitude'], row['longitude'])\n",
    "            messed_up_s2id_count = messed_up_s2id_count+1\n",
    "    print(f\"Fixed {messed_up_s2id_count} messed up s2ids\")\n",
    "\n",
    "    # handle duplicates\n",
    "\n",
    "    old_len = len(df)\n",
    "\n",
    "    dupes = df[df.duplicated(subset='s2id', keep=False)]\n",
    "    print(f\"There are {len(dupes)} duplicate rows across {len(np.unique(dupes['s2id']))} s2ids\")\n",
    "    if len(dupes) > 0:\n",
    "        print(f\"\\n ** START DUPLICATE INFO ** \")\n",
    "        \n",
    "        dupes1 = dupes[['s2id','latitude','longitude']]\n",
    "\n",
    "        conflicting_ids = (\n",
    "            dupes1.groupby('s2id')\n",
    "            .nunique(dropna=False)          # count distinct values per column\n",
    "            .gt(1)                          # flag columns with >1 unique value\n",
    "            .any(axis=1)                    # True if any column differs\n",
    "        )\n",
    "        conflicting_ids = conflicting_ids[conflicting_ids].index\n",
    "\n",
    "        # Filter and order\n",
    "        conflicting_rows = dupes1[dupes1['s2id'].isin(conflicting_ids)]\n",
    "        print(f\"Different lat/lons: {len(conflicting_rows)} duplicate rows with {len(np.unique(conflicting_rows['s2id']))} s2ids\")\n",
    "\n",
    "\n",
    "        dupes1 = dupes[['s2id','label','sublabel','iso3']]\n",
    "\n",
    "        conflicting_ids = (\n",
    "            dupes1.groupby('s2id')\n",
    "            .nunique(dropna=False)          # count distinct values per column\n",
    "            .gt(1)                          # flag columns with >1 unique value\n",
    "            .any(axis=1)                    # True if any column differs\n",
    "        )\n",
    "        conflicting_ids = conflicting_ids[conflicting_ids].index\n",
    "\n",
    "        # Filter and order\n",
    "        conflicting_rows = dupes1[dupes1['s2id'].isin(conflicting_ids)].sort_values(by='s2id')\n",
    "        print(f\"Different labels/sublabels: {len(conflicting_rows)} duplicate rows with {len(np.unique(conflicting_rows['s2id']))} s2ids:\")\n",
    "        print(conflicting_rows)\n",
    "\n",
    "\n",
    "    if duplicate_option == 'keep_last':\n",
    "        df = df.drop_duplicates(subset='s2id', keep='last').reset_index(drop=True)\n",
    "        print(f\"Dropped {old_len - len(df)} duplicates\")\n",
    "        if len(dupes) > 0:\n",
    "            print(f\"** END DUPLICATE INFO ** \\n\")\n",
    "    elif duplicate_option == 'combine_with_ampersand':\n",
    "        # Filter to duplicated s2ids (includes all occurrences)\n",
    "        dupes = df[df.duplicated(subset='s2id', keep=False)]\n",
    "\n",
    "        # Group by s2id so you can loop through each set of duplicates\n",
    "\n",
    "        n_labels_combined = 0\n",
    "        n_sublabels_combined = 0\n",
    "\n",
    "        for s2id, group in dupes.groupby('s2id'):\n",
    "            max_idx = group.index.max()\n",
    "\n",
    "            if len(np.unique(group['label'])) > 1:\n",
    "                s = ''\n",
    "                for x in np.unique(group['label']):\n",
    "                    if pd.isna(x):\n",
    "                        pass\n",
    "                    elif len(s) == 0:\n",
    "                        s = x\n",
    "                    else:\n",
    "                        s = f\"{s} & {x}\"\n",
    "                if len(s) > 0:\n",
    "                    df.loc[max_idx, 'label'] = s\n",
    "                    n_labels_combined = n_labels_combined + len(group) - 1\n",
    "\n",
    "            if group['sublabel'].nunique(dropna=False) > 1: # can handle None\n",
    "                s = ''\n",
    "                for x in np.unique(group['sublabel']):\n",
    "                    if pd.isna(x):\n",
    "                        pass\n",
    "                    elif len(s) == 0:\n",
    "                        s = x\n",
    "                    else:\n",
    "                        s = f\"{s} & {x}\"\n",
    "                if len(s) > 0:\n",
    "                    df.loc[max_idx, 'sublabel'] = s\n",
    "                    n_sublabels_combined = n_sublabels_combined + len(group) - 1\n",
    "\n",
    "            idxs = list(group.index)\n",
    "            idxs.remove(max(idxs))\n",
    "                \n",
    "            df = df.drop(index=idxs)\n",
    "            \n",
    "        df = df.reset_index(drop=True)\n",
    "        print(f\"Handled {old_len - len(df)} duplicates\")\n",
    "        print(f\"Rows whose labels were combined: {n_labels_combined}\")\n",
    "        print(f\"Rows whose sublabels were combined: {n_sublabels_combined}\")\n",
    "    \n",
    "    elif duplicate_option == 'nothing':\n",
    "        dupes = df[df.duplicated(subset='s2id', keep=False)]\n",
    "        if len(dupes) > 0:\n",
    "            print(f\"WARNING: There are {len(dupes)} duplicated s2ids that were not handled\")\n",
    "        else:\n",
    "            print(f\"There are 0 duplicated s2ids\")\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"invalid duplicate option, should be unreachable\")\n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24faec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args=None):\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--output_filename\",\n",
    "        type=str,\n",
    "        required=True,           # force the user to supply it\n",
    "        help=\"Name of the output file\"\n",
    "    )\n",
    "\n",
    "    parsed = parser.parse_args(args[1:])   # skip program name\n",
    "    print(\"Output file:\", parsed.output_file)\n",
    "\n",
    "    overrides_filename = f\"{PORT_LIST_FLDR}/overrides_file_order.txt\"\n",
    "    combined_anchorages = []\n",
    "    with open(overrides_filename, \"r\") as file:\n",
    "        for i, line in enumerate(file):\n",
    "            line = line.strip()\n",
    "\n",
    "            if i == 0:\n",
    "                # first line\n",
    "                print(f\"\\nAdding overrides from {line}...\")\n",
    "                combined_anchorages = pd.read_csv(f\"{PORT_LIST_FLDR}/{line}\")\n",
    "                combined_anchorages = clean_overrides(combined_anchorages, duplicate_option='keep_last')\n",
    "                combined_anchorages['source']=line\n",
    "            else:\n",
    "                print(f\"\\nAdding overrides from {line}...\")\n",
    "                df = pd.read_csv(f\"{PORT_LIST_FLDR}/{line}\")\n",
    "                df = clean_overrides(df, duplicate_option='keep_last')\n",
    "                df['source'] = line\n",
    "\n",
    "                combined_anchorages = pd.concat([combined_anchorages,df])\n",
    "                mask = combined_anchorages.duplicated(subset='s2id', keep='last')\n",
    "                dropped = combined_anchorages[mask].copy() \n",
    "                old_len = len(combined_anchorages)\n",
    "                combined_anchorages = combined_anchorages[~mask].reset_index(drop=True)\n",
    "                overwrite_count = old_len - len(combined_anchorages)\n",
    "                if overwrite_count > 0:\n",
    "                    print(f\"** OVERWROTE {old_len - len(combined_anchorages)} s2ids FROM PREVIOUS OVERRIDE FILES **\")\n",
    "                    drop_counts = dropped['source'].value_counts()\n",
    "                    for source, count in drop_counts.items():\n",
    "                        print(f\"- {count} s2ids from {source} were overwritten\")\n",
    "    \n",
    "    combined_anchorages.to_csv(f\"{PORT_LIST_FLDR}/{parsed.output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sys.exit(run(args=sys.argv))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "rad_map",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
